{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ReasonForge\n",
        "\n",
        "Deterministic math & code tools for small language models.\n",
        "\n",
        "1. Clone repo & install deps\n",
        "2. Install Ollama & pull model\n",
        "3. Sanity tests\n",
        "4. MATH-500 / HumanEval benchmarks\n",
        "5. Gradio chat UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_setup"
      },
      "source": [
        "---\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_and_install"
      },
      "outputs": [],
      "source": [
        "# Clone repo & install deps\n",
        "!git clone https://github.com/RoyCoding8/MCP.git /content/MCP 2>/dev/null || echo 'Already cloned'\n",
        "!pip install -q \"requests>=2.31.0\" \"gradio>=6.0\" \"sympy>=1.13.0\" \"datasets>=4.6.1\" \"math-verify[antlr4_13_2]>=0.9.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_ollama"
      },
      "outputs": [],
      "source": [
        "# Install Ollama\n",
        "!sudo apt-get install -qq zstd > /dev/null 2>&1\n",
        "!curl -fsSL https://ollama.com/install.sh | sh > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start_ollama"
      },
      "outputs": [],
      "source": [
        "import subprocess, time, os\n",
        "import requests\n",
        "\n",
        "MODELS_PATH = '/content/ollama_models'\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "print(f'Models path: {MODELS_PATH}')\n",
        "\n",
        "subprocess.run(['pkill', '-f', 'ollama'], capture_output=True)\n",
        "time.sleep(2)\n",
        "\n",
        "env = os.environ.copy()\n",
        "env['OLLAMA_MODELS'] = MODELS_PATH\n",
        "env['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "env['OLLAMA_NUM_PARALLEL'] = '2'\n",
        "\n",
        "print(\"Starting Ollama server...\")\n",
        "log_file = open('/content/ollama_server.log', 'w')\n",
        "proc = subprocess.Popen(\n",
        "    ['ollama', 'serve'],\n",
        "    env=env,\n",
        "    stdout=log_file,\n",
        "    stderr=subprocess.STDOUT,\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "while time.time()-start < 30:\n",
        "    try:\n",
        "        requests.get('http://localhost:11434/')\n",
        "        print(f'Ollama ready ({time.time()-start:.2f}s)')\n",
        "        break\n",
        "    except requests.ConnectionError:\n",
        "        time.sleep(1)\n",
        "else:\n",
        "    print('Ollama failed to start â€” check /content/ollama_server.log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pull_model",
        "outputId": "9762058d-d270-4859-8319-78ced88b474a"
      },
      "outputs": [],
      "source": [
        "# Pull Models\n",
        "MODELS = ['qwen3:8b']\n",
        "\n",
        "for MODEL in MODELS:\n",
        "    print(f'Pulling {MODEL}...')\n",
        "    !OLLAMA_MODELS={MODELS_PATH} ollama pull {MODEL}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_verify"
      },
      "source": [
        "---\n",
        "## Verify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sanity_tests"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/MCP')\n",
        "!python -m tests.sanity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_benchmarks"
      },
      "source": [
        "---\n",
        "## Benchmarks\n",
        "\n",
        "A/B comparison: Baseline (no tools) vs ReasonForge (with tools)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "math_benchmark"
      },
      "outputs": [],
      "source": [
        "# MATH-500 Benchmark\n",
        "N_MATH = 50\n",
        "SKIP_BASELINE = False\n",
        "THINK = False\n",
        "\n",
        "from google.colab import userdata\n",
        "try: os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "except: print(\"HF_TOKEN not found in Secrets.\")\n",
        "\n",
        "os.chdir('/content/MCP')\n",
        "cmd = f'python -m tests.benchmark --model {MODEL} --n {N_MATH}'\n",
        "if SKIP_BASELINE: cmd += ' --skip-baseline'\n",
        "if THINK: cmd += ' --think'\n",
        "print(f'Running: {cmd}\\n')\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_benchmark"
      },
      "outputs": [],
      "source": [
        "# HumanEval Code Benchmark\n",
        "N_CODE = 20\n",
        "SKIP_BASELINE_CODE = False\n",
        "THINK_CODE = True\n",
        "\n",
        "os.chdir('/content/MCP')\n",
        "cmd = f'python -m tests.code_benchmark --model {MODEL} --n {N_CODE}'\n",
        "if SKIP_BASELINE_CODE: cmd += ' --skip-baseline'\n",
        "if THINK_CODE: cmd += ' --think'\n",
        "print(f'Running: {cmd}\\n')\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_ui"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch_ui"
      },
      "outputs": [],
      "source": [
        "os.environ['RF_SHARE'] = '1'\n",
        "os.chdir('/content/MCP')\n",
        "\n",
        "!python -u -m ui.app | tee -a /content/ollama_server.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9dsarqNmgUN"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ollama_status"
      },
      "outputs": [],
      "source": [
        "# !OLLAMA_MODELS=$MODELS_PATH ollama ps\n",
        "# print()\n",
        "# !OLLAMA_MODELS=$MODELS_PATH ollama list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cleanup"
      },
      "outputs": [],
      "source": [
        "# !rm -rf /content/MCP\n",
        "# !rm /content/ollama_server.log"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "G4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}